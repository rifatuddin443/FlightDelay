Epoch 001 | Loss 0.9464 | Val MAE 6.8037 R2 -0.2921 RMSE 10.0399
[Checkpoint] New minimum MAE 6.8037 at epoch 1, model saved.
d:\python\STPN-main\dptrainsave1.py:272: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.
Consider using tensor.detach() first. (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\pytorch\torch\csrc\autograd\generated\python_variable_methods.cpp:836.)
  log_row = {'epoch': ep, 'loss': float(loss), 'mae': mean_mae, 'r2': mean_r2, 'rmse': mean_rmse}
Epoch 002 | Loss 1.4488 | Val MAE 7.1223 R2 -0.1914 RMSE 9.6407
Epoch 003 | Loss 4.0104 | Val MAE 7.2672 R2 -0.2012 RMSE 9.6804
Epoch 004 | Loss 2.9648 | Val MAE 7.2985 R2 -0.1794 RMSE 9.5922
Epoch 005 | Loss 3.1005 | Val MAE 7.3015 R2 -0.1746 RMSE 9.5726
Epoch 006 | Loss 1.0155 | Val MAE 7.1307 R2 -0.1406 RMSE 9.4331
Epoch 007 | Loss 1.0123 | Val MAE 7.0471 R2 -0.1006 RMSE 9.2661
Epoch 008 | Loss 0.8783 | Val MAE 67.9193 R2 -205.7153 RMSE 126.9899
Epoch 009 | Loss 0.8690 | Val MAE 38.7094 R2 -39.2984 RMSE 56.0695
Epoch 010 | Loss 0.8866 | Val MAE 38.3499 R2 -34.4614 RMSE 52.5968
Epoch 011 | Loss 0.8562 | Val MAE 21.1029 R2 -12.3417 RMSE 32.2617
Epoch 012 | Loss 0.8899 | Val MAE 57.0283 R2 -89.3612 RMSE 83.9603
Epoch 013 | Loss 0.8838 | Val MAE 62.9574 R2 -72.6179 RMSE 75.7835
Epoch 014 | Loss 0.8499 | Val MAE 255.3472 R2 -1002.0405 RMSE 279.7321
Epoch 015 | Loss 0.8701 | Val MAE 186.1315 R2 -572.6823 RMSE 211.5528
Epoch 016 | Loss 0.8775 | Val MAE 264.5161 R2 -1179.1684 RMSE 303.4276
Epoch 017 | Loss 0.8684 | Val MAE 156.4880 R2 -436.3398 RMSE 184.7109
Epoch 018 | Loss 0.8600 | Val MAE 178.2136 R2 -586.1923 RMSE 214.0293
Epoch 019 | Loss 0.8907 | Val MAE 211.7378 R2 -757.3143 RMSE 243.2247
Epoch 020 | Loss 0.8657 | Val MAE 299.5029 R2 -1487.3863 RMSE 340.7540
Epoch 021 | Loss 0.8456 | Val MAE 297.6231 R2 -1559.3860 RMSE 348.8985
Epoch 022 | Loss 0.8697 | Val MAE 301.9359 R2 -1760.6081 RMSE 370.7129
Epoch 023 | Loss 0.8526 | Val MAE 396.5873 R2 -3222.5564 RMSE 501.4767
Epoch 024 | Loss 0.8567 | Val MAE 461.7711 R2 -4140.7238 RMSE 568.4256
Epoch 025 | Loss 0.8985 | Val MAE 390.9352 R2 -3384.1052 RMSE 513.8888
Epoch 026 | Loss 0.8523 | Val MAE 137.2246 R2 -584.2058 RMSE 213.6669
Epoch 027 | Loss 0.8581 | Val MAE 183.0730 R2 -1000.9514 RMSE 279.5802
Epoch 028 | Loss 0.8573 | Val MAE 219.4582 R2 -1188.6293 RMSE 304.6414
Epoch 029 | Loss 0.8598 | Val MAE 205.7708 R2 -1016.3320 RMSE 281.7179
Epoch 030 | Loss 0.8677 | Val MAE 184.3890 R2 -732.0412 RMSE 239.1373
Epoch 031 | Loss 0.8743 | Val MAE 154.2908 R2 -490.1061 RMSE 195.7360
Epoch 032 | Loss 0.8633 | Val MAE 490.7573 R2 -4795.1078 RMSE 611.6846
Epoch 033 | Loss 0.8709 | Val MAE 166.2131 R2 -721.5751 RMSE 237.4240
Epoch 034 | Loss 0.8677 | Val MAE 280.0202 R2 -1633.4913 RMSE 357.0873
Epoch 035 | Loss 0.8879 | Val MAE 444.4944 R2 -3680.9783 RMSE 535.9493
Epoch 036 | Loss 0.8783 | Val MAE 269.4915 R2 -1373.1028 RMSE 327.4106
Epoch 037 | Loss 0.8276 | Val MAE 144.0068 R2 -403.3220 RMSE 177.6015
Epoch 038 | Loss 0.8466 | Val MAE 103.3090 R2 -237.5972 RMSE 136.4318
Epoch 039 | Loss 0.8750 | Val MAE 102.9507 R2 -208.8654 RMSE 127.9539
Epoch 040 | Loss 0.8669 | Val MAE 67.2377 R2 -101.3971 RMSE 89.3772
Epoch 041 | Loss 0.8478 | Val MAE 63.0679 R2 -81.3739 RMSE 80.1635
Epoch 042 | Loss 0.8834 | Val MAE 74.9222 R2 -104.2966 RMSE 90.6337
Epoch 043 | Loss 0.8776 | Val MAE 71.4001 R2 -84.2491 RMSE 81.5507
Epoch 044 | Loss 0.8571 | Val MAE 31.7392 R2 -22.5070 RMSE 42.8232
Epoch 045 | Loss 0.8609 | Val MAE 25.1057 R2 -13.8088 RMSE 33.9891
Epoch 046 | Loss 0.8630 | Val MAE 24.9090 R2 -13.0329 RMSE 33.0868
Epoch 047 | Loss 0.8738 | Val MAE 24.0016 R2 -17.8902 RMSE 38.3879
Epoch 048 | Loss 0.8546 | Val MAE 27.2906 R2 -22.1556 RMSE 42.5013
Epoch 049 | Loss 0.8835 | Val MAE 71.7272 R2 -131.9160 RMSE 101.8288
Epoch 050 | Loss 0.8513 | Val MAE 14.8635 R2 -5.2948 RMSE 22.1588