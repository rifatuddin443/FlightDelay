turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
09/18/2025 15:55:43:WARNING:Ignoring drop_last as it is not compatible with DPDataLoader.
[DP] Using noise_multiplier=1.5, max_grad_norm=1.5
start training...
Training metrics will be saved to: noise_multiplier=1.5_max_grad_norm=1.5.csv
D:\flight delay\stpn paper\STPN-main\training_u_diffrentialprivacy - lstm.py:322: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.
  loss.backward()
Epoch 001 | Train Loss 0.9958 | Val Loss 1.1390 | Val MAE 9.4503 R2 -0.5093 RMSE 12.0451 | ε ~ 0.06, δ=1e-05
Epoch 002 | Train Loss 0.9877 | Val Loss 1.1300 | Val MAE 9.4315 R2 -0.4853 RMSE 11.9493 | ε ~ 0.09, δ=1e-05
Epoch 003 | Train Loss 0.9779 | Val Loss 1.1264 | Val MAE 9.4603 R2 -0.4759 RMSE 11.9114 | ε ~ 0.11, δ=1e-05
Epoch 004 | Train Loss 0.9755 | Val Loss 1.1202 | Val MAE 9.4501 R2 -0.4596 RMSE 11.8455 | ε ~ 0.12, δ=1e-05
Epoch 005 | Train Loss 0.9683 | Val Loss 1.1169 | Val MAE 9.4849 R2 -0.4510 RMSE 11.8105 | ε ~ 0.14, δ=1e-05
Epoch 006 | Train Loss 0.9643 | Val Loss 1.1116 | Val MAE 9.4731 R2 -0.4369 RMSE 11.7528 | ε ~ 0.15, δ=1e-05
Epoch 007 | Train Loss 0.9620 | Val Loss 1.1087 | Val MAE 9.4718 R2 -0.4293 RMSE 11.7219 | ε ~ 0.16, δ=1e-05
Epoch 008 | Train Loss 0.9601 | Val Loss 1.1064 | Val MAE 9.4835 R2 -0.4234 RMSE 11.6975 | ε ~ 0.18, δ=1e-05
Epoch 009 | Train Loss 0.9575 | Val Loss 1.1021 | Val MAE 9.4772 R2 -0.4120 RMSE 11.6506 | ε ~ 0.19, δ=1e-05
Epoch 010 | Train Loss 0.9547 | Val Loss 1.1002 | Val MAE 9.4852 R2 -0.4073 RMSE 11.6311 | ε ~ 0.20, δ=1e-05
Epoch 011 | Train Loss 0.9555 | Val Loss 1.0963 | Val MAE 9.4561 R2 -0.3971 RMSE 11.5887 | ε ~ 0.21, δ=1e-05
Epoch 012 | Train Loss 0.9548 | Val Loss 1.0952 | Val MAE 9.4531 R2 -0.3942 RMSE 11.5769 | ε ~ 0.22, δ=1e-05
Epoch 013 | Train Loss 0.9550 | Val Loss 1.0936 | Val MAE 9.4475 R2 -0.3900 RMSE 11.5593 | ε ~ 0.23, δ=1e-05
Epoch 014 | Train Loss 0.9543 | Val Loss 1.0906 | Val MAE 9.4245 R2 -0.3826 RMSE 11.5284 | ε ~ 0.23, δ=1e-05
Epoch 015 | Train Loss 0.9532 | Val Loss 1.0881 | Val MAE 9.4068 R2 -0.3759 RMSE 11.5004 | ε ~ 0.24, δ=1e-05
Epoch 016 | Train Loss 0.9525 | Val Loss 1.0854 | Val MAE 9.3782 R2 -0.3689 RMSE 11.4712 | ε ~ 0.25, δ=1e-05
Epoch 017 | Train Loss 0.9531 | Val Loss 1.0847 | Val MAE 9.3845 R2 -0.3671 RMSE 11.4637 | ε ~ 0.26, δ=1e-05
Epoch 018 | Train Loss 0.9533 | Val Loss 1.0812 | Val MAE 9.3528 R2 -0.3585 RMSE 11.4277 | ε ~ 0.27, δ=1e-05
Epoch 019 | Train Loss 0.9516 | Val Loss 1.0784 | Val MAE 9.3309 R2 -0.3513 RMSE 11.3973 | ε ~ 0.27, δ=1e-05
Epoch 020 | Train Loss 0.9524 | Val Loss 1.0759 | Val MAE 9.2930 R2 -0.3453 RMSE 11.3717 | ε ~ 0.28, δ=1e-05
Epoch 021 | Train Loss 0.9513 | Val Loss 1.0708 | Val MAE 9.2365 R2 -0.3326 RMSE 11.3180 | ε ~ 0.29, δ=1e-05
Epoch 022 | Train Loss 0.9525 | Val Loss 1.0692 | Val MAE 9.2140 R2 -0.3285 RMSE 11.3003 | ε ~ 0.30, δ=1e-05
Epoch 023 | Train Loss 0.9503 | Val Loss 1.0647 | Val MAE 9.1625 R2 -0.3172 RMSE 11.2521 | ε ~ 0.30, δ=1e-05
Epoch 024 | Train Loss 0.9498 | Val Loss 1.0649 | Val MAE 9.1736 R2 -0.3177 RMSE 11.2540 | ε ~ 0.31, δ=1e-05
Epoch 025 | Train Loss 0.9501 | Val Loss 1.0568 | Val MAE 9.0895 R2 -0.2977 RMSE 11.1682 | ε ~ 0.32, δ=1e-05
Epoch 026 | Train Loss 0.9514 | Val Loss 1.0473 | Val MAE 8.9704 R2 -0.2749 RMSE 11.0693 | ε ~ 0.32, δ=1e-05
Epoch 027 | Train Loss 0.9504 | Val Loss 1.0473 | Val MAE 8.9704 R2 -0.2746 RMSE 11.0680 | ε ~ 0.33, δ=1e-05
Epoch 028 | Train Loss 0.9485 | Val Loss 1.0445 | Val MAE 8.9373 R2 -0.2679 RMSE 11.0388 | ε ~ 0.34, δ=1e-05
Epoch 029 | Train Loss 0.9484 | Val Loss 1.0408 | Val MAE 8.8926 R2 -0.2591 RMSE 10.9999 | ε ~ 0.34, δ=1e-05
Epoch 030 | Train Loss 0.9488 | Val Loss 1.0373 | Val MAE 8.8497 R2 -0.2507 RMSE 10.9634 | ε ~ 0.35, δ=1e-05
Epoch 031 | Train Loss 0.9497 | Val Loss 1.0302 | Val MAE 8.7644 R2 -0.2338 RMSE 10.8886 | ε ~ 0.35, δ=1e-05
Epoch 032 | Train Loss 0.9477 | Val Loss 1.0275 | Val MAE 8.7351 R2 -0.2272 RMSE 10.8592 | ε ~ 0.36, δ=1e-05
Epoch 033 | Train Loss 0.9485 | Val Loss 1.0256 | Val MAE 8.7176 R2 -0.2223 RMSE 10.8379 | ε ~ 0.37, δ=1e-05
Epoch 034 | Train Loss 0.9460 | Val Loss 1.0231 | Val MAE 8.6874 R2 -0.2162 RMSE 10.8105 | ε ~ 0.37, δ=1e-05
Epoch 035 | Train Loss 0.9463 | Val Loss 1.0268 | Val MAE 8.7282 R2 -0.2249 RMSE 10.8495 | ε ~ 0.38, δ=1e-05
Epoch 036 | Train Loss 0.9466 | Val Loss 1.0299 | Val MAE 8.7660 R2 -0.2323 RMSE 10.8823 | ε ~ 0.38, δ=1e-05
Epoch 037 | Train Loss 0.9474 | Val Loss 1.0262 | Val MAE 8.7115 R2 -0.2233 RMSE 10.8424 | ε ~ 0.39, δ=1e-05
Epoch 038 | Train Loss 0.9467 | Val Loss 1.0270 | Val MAE 8.7326 R2 -0.2252 RMSE 10.8509 | ε ~ 0.39, δ=1e-05
Epoch 039 | Train Loss 0.9458 | Val Loss 1.0238 | Val MAE 8.6875 R2 -0.2175 RMSE 10.8168 | ε ~ 0.40, δ=1e-05
Epoch 040 | Train Loss 0.9466 | Val Loss 1.0228 | Val MAE 8.6682 R2 -0.2151 RMSE 10.8059 | ε ~ 0.41, δ=1e-05
Epoch 041 | Train Loss 0.9460 | Val Loss 1.0215 | Val MAE 8.6683 R2 -0.2117 RMSE 10.7909 | ε ~ 0.41, δ=1e-05
Epoch 042 | Train Loss 0.9442 | Val Loss 1.0176 | Val MAE 8.6217 R2 -0.2025 RMSE 10.7496 | ε ~ 0.42, δ=1e-05
Epoch 043 | Train Loss 0.9443 | Val Loss 1.0156 | Val MAE 8.6002 R2 -0.1979 RMSE 10.7289 | ε ~ 0.42, δ=1e-05
Epoch 044 | Train Loss 0.9437 | Val Loss 1.0135 | Val MAE 8.5763 R2 -0.1932 RMSE 10.7079 | ε ~ 0.43, δ=1e-05
Epoch 045 | Train Loss 0.9444 | Val Loss 1.0110 | Val MAE 8.5445 R2 -0.1869 RMSE 10.6799 | ε ~ 0.43, δ=1e-05
Epoch 046 | Train Loss 0.9434 | Val Loss 1.0051 | Val MAE 8.4647 R2 -0.1732 RMSE 10.6175 | ε ~ 0.44, δ=1e-05
Epoch 047 | Train Loss 0.9430 | Val Loss 1.0017 | Val MAE 8.4230 R2 -0.1653 RMSE 10.5817 | ε ~ 0.44, δ=1e-05
Epoch 048 | Train Loss 0.9410 | Val Loss 1.0026 | Val MAE 8.4276 R2 -0.1671 RMSE 10.5898 | ε ~ 0.45, δ=1e-05
Epoch 049 | Train Loss 0.9431 | Val Loss 1.0006 | Val MAE 8.4028 R2 -0.1625 RMSE 10.5685 | ε ~ 0.45, δ=1e-05
Epoch 050 | Train Loss 0.9429 | Val Loss 1.0030 | Val MAE 8.4250 R2 -0.1678 RMSE 10.5930 | ε ~ 0.46, δ=1e-05
Saved weights to: spdpnUS.pth

3 step ahead arrival delay, Test MAE: 10.3885 min, Test R2: -0.1440, Test RMSE: 12.9309 min
6 step ahead arrival delay, Test MAE: 10.3869 min, Test R2: -0.1438, Test RMSE: 12.9302 min
12 step ahead arrival delay, Test MAE: 10.3868 min, Test R2: -0.1433, Test RMSE: 12.9306 min
3 step ahead departure delay, Test MAE: 6.5721 min, Test R2: -0.0487, Test RMSE: 9.1581 min
6 step ahead departure delay, Test MAE: 6.5788 min, Test R2: -0.0499, Test RMSE: 9.1647 min
12 step ahead departure delay, Test MAE: 6.5826 min, Test R2: -0.0505, Test RMSE: 9.1699 min